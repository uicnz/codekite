---
title: Build a Docstring Search Engine
---

In this tutorial you’ll build a semantic search tool on top of `kit`
using **docstring-based indexing**. 

Why docstrings?  Summaries distill *intent* rather than syntax.  Embedding these
short natural-language strings lets the vector DB focus on meaning, giving you
relevant hits even when the literal code differs (e.g., `retry()` vs
`attempt_again()`).  It also keeps the index small (one embedding per file or
symbol instead of dozens of raw-code chunks).

---

## 1. Install dependencies

```bash
uv pip install kit[openai] sentence-transformers chromadb
```

## 2. Initialise a repo and summarizer

```python
import kit
from sentence_transformers import SentenceTransformer

REPO_PATH = "/path/to/your/project"
repo = kit.Repository(REPO_PATH)

summarizer = repo.get_summarizer()  # defaults to OpenAIConfig
```

## 3. Build the docstring index

```python
embed_model = SentenceTransformer("all-MiniLM-L6-v2")
embed_fn = lambda txt: embed_model.encode(txt).tolist()

indexer = kit.DocstringIndexer(repo, summarizer, embed_fn)
indexer.build()          # writes .kit/docstring_db
```

The first run will take time depending on repo size and LLM latency.
Summaries are cached inside the vector DB, so subsequent runs are cheap.

## 4. Query the index

```python
searcher = kit.SummarySearcher(indexer)

results = searcher.search("How is the retry back-off implemented?", top_k=3)
for hit in results:
    print("→", hit["file"], "\n", hit["summary"])
```

You now have a semantic code searcher, using powerful docstring summaries,
as easy as that.

